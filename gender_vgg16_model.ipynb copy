{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import cv2\n",
    "import dlib\n",
    "from contextlib import contextmanager\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('wiki_crop/wiki.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = mat['wiki'][0][0][0].shape[1]\n",
    "columns = [\"dob\", \"photo_taken\", \"full_path\", \"gender\", \"name\", \"face_location\", \"face_score\", \"second_face_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index = range(0,instances), columns = columns)\n",
    "\n",
    "for i in mat:\n",
    "    if i == \"wiki\":\n",
    "        current_array = mat[i][0][0]\n",
    "        for j in range(len(current_array)):\n",
    "            df[columns[j]] = pd.DataFrame(current_array[j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datenum_to_datetime(datenum):\n",
    "    days = datenum % 1\n",
    "    hours = days % 1 * 24\n",
    "    minutes = hours % 1 * 60\n",
    "    seconds = minutes % 1 * 60\n",
    "    \n",
    "    exact_date = datetime.fromordinal(int(datenum)) + timedelta(days=int(days)) + timedelta(hours=int(hours)) + timedelta(minutes=int(minutes)) + timedelta(seconds=round(seconds)) - timedelta(days=366)\n",
    "    \n",
    "    \n",
    "    return exact_date.year\n",
    "\n",
    "df['date_of_birth'] = df['dob'].apply(datenum_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['photo_taken'] - df['date_of_birth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove pictures does not include face\n",
    "df = df[df['face_score'] != -np.inf]\n",
    " \n",
    "#some pictures include more than one face, remove them\n",
    "df = df[df['second_face_score'].isna()]\n",
    " \n",
    "#check threshold\n",
    "df = df[df['face_score'] >= 3]\n",
    " \n",
    "#some records do not have a gender information\n",
    "df = df[~df['gender'].isna()]\n",
    " \n",
    "df = df.drop(columns = ['name','face_score','second_face_score','date_of_birth','face_location'])\n",
    "\n",
    "#some guys seem to be greater than 100. some of these are paintings. remove these old guys\n",
    "df = df[df['age'] <= 100]\n",
    " \n",
    "#some guys seem to be unborn in the data set\n",
    "df = df[df['age'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)\n",
    "def getImagePixels(image_path):\n",
    "    img = image.load_img(\"wiki_crop/%s\" % image_path[0], grayscale=False, target_size=target_size)\n",
    "    x = image.img_to_array(img).reshape(1, -1)[0]\n",
    "    #x = preprocess_input(x)\n",
    "    return x\n",
    " \n",
    "df['pixels'] = df['full_path'].apply(getImagePixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['gender'].values\n",
    "target_classes = keras.utils.to_categorical(target, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = df['pixels'].values\n",
    "features = []\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    features.append(df['pixels'].values[i])\n",
    "\n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22138, 224, 224, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features /= 255 #normalize in [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see above, the last dense layer has 1000 output nodes, but we only need 2, thus add all other layers except last one.\n",
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model.add(layer)\n",
    "    \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(features, target_classes, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19924 samples, validate on 2214 samples\n",
      "Epoch 1/13\n",
      " 2112/19924 [==>...........................] - ETA: 52:53 - loss: 0.5977 - acc: 0.7003"
     ]
    }
   ],
   "source": [
    "# Without training batches\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=13, validation_data=(x_valid, y_valid), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gender_wiki_new.h5')\n",
    "model.save_weights('gender_wiki_new_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []; actual_list = []\n",
    "\n",
    "for i in predictions:\n",
    "    pred_list.append(np.argmax(i))\n",
    "\n",
    "for i in test_y: \n",
    "    actual_list.append(np.argmax(i))\n",
    "\n",
    "confusion_matrix(actual_list, pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loadImage(filepath):\n",
    "#     test_img = image.load_img(filepath, target_size=(224, 224))\n",
    "#     test_img = image.img_to_array(test_img)\n",
    "#     test_img = np.expand_dims(test_img, axis = 0)\n",
    "#     test_img /= 255\n",
    "#     return test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picture = \"jackman.jpg\"\n",
    "\n",
    "# prediction = model.predict(loadImage(picture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = image.load_img(picture)#, target_size=(224, 224))\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "# gender = \"Man\" if np.argmax(prediction) == 1 else \"Woman\"\n",
    "\n",
    "# print(\"gender: \", gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For face detection\n",
    "\n",
    "# face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while(True):\n",
    "#     ret, img = cap.read()\n",
    "    \n",
    "#     faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "#     for (x,y,w,h) in faces:\n",
    "#         if w > 130:\n",
    "#             cv2.rectangle(img,(x,y), (x+w, y+h), (128,128,1))\n",
    "            \n",
    "#             # extracted detected face\n",
    "#             detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "            \n",
    "            \n",
    "#             try:\n",
    "#                 #age gender data set has 40% margin around the face. expand detected face.\n",
    "#                 margin = 30\n",
    "#                 margin_x = int((w*margin)/100); margin_y = int((h*margin)/100)\n",
    "#                 detected_face = img[int(y-margin_y):int(y+h+margin_y), int(x-margin_x):int(x+w+margin_x)]\n",
    "                \n",
    "#             except:\n",
    "#                 print(\"Detected face has no margin\")\n",
    "                \n",
    "#             try:\n",
    "#                 detected_face = cv2.resize(detected_face, (224, 224))\n",
    "                \n",
    "#                 img_pixels = image.img_to_array(detected_face)\n",
    "#                 img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "#                 img_pixels /= 255\n",
    "                \n",
    "#                 #find out age and gender\n",
    "#                 gender_distribution = model.predict(img_pixels)[0]\n",
    "#                 gender_index = np.argmax(gender_distribution)\n",
    "                \n",
    "#                 if gender_index == 0: \n",
    "#                     gender = \"Female\"\n",
    "#                 else:\n",
    "#                     gender = \"Man\"\n",
    "                    \n",
    "#                 #background for age gender declaration\n",
    "#                 info_box_color = (46,200,255)\n",
    "#                 triangle_cnt = np.array( [(x+int(w/2), y), (x+int(w/2)-20, y-20), (x+int(w/2)+20, y-20)] )\n",
    "#                 cv2.drawContours(img, [triangle_cnt], 0, info_box_color, -1)\n",
    "#                 cv2.rectangle(img,(x+int(w/2)-50,y-20),(x+int(w/2)+50,y-90),info_box_color,cv2.FILLED)\n",
    "            \n",
    "#                 cv2.putText(img, gender, (x+int(w/2)-42, y - 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(\"expection\", str(e))\n",
    "#     cv2.imshow('Window', img)\n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == 27:\n",
    "#         break\n",
    "        \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
